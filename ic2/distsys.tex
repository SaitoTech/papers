
Understanding the three types of \textit{goal conflict} that \textit{TFMs} must eliminate lets us examine previous research with less pessimism than its authors may have intended. While the papers discussed below have pushed us towards a deeper understanding of the limits of auction mechanisms, their conclusions do not hold for indirect mechanisms which do not target \textit{pareto optimality} as their social choice rule.

In academia, early attempts to model \textit{TFMs} as auctions were Bitcoin-specific, starting with "Redesigning Bitcoin's Fee Market", which proposed using a "monopolistic auction" to stabilize miner revenue, and then Andrew Yao's "An Incentive Analysis" which showed this maximized miner revenue at scale. Basu, Easley, Oâ€™Hara, Sirer then proposed a modified Vickrey-Clarke-Groves mechanism to better maximize the collective welfare of both users and miners. This concern over maximizing the welfare of multiple classes of participants showed awareness that efficiency mattered and that maximizing collective welfare was the essential economic problem! Within a decade of the invention of Bitcoin, computer science was on the cusp of realizing that \textit{pareto optimality} was the social choice rule required for efficient on-chain scaling.

The rise of Ethereum and the blocksize wars it unleashed pulled public attention away from proof-of-work, and computer science responded in 2021 when Tim Roughgarden\citet{roughgarden2021,roughgarden2024transaction} offered a paper that modelled Transaction Fee Mechanisms (TFMs) as two-sided auctions in which block producers are given a temporary monopoly over the production of a block and must strategically allocate a subset of transactions into it. Looking beyond Bitcoin towards the emerging landscape of competing approaches, Roughgarden attempted to generalize the limitations developers were experiencing in both proof-of-work and proof-of-stake appraoches into an abstract model whose limitations could be theoretically analyzed. As a result, Roughgarden was the first to highlight the difficulty of achieving incentive compatibility for both users (UIC) and block producers or miners (MIC) as a general problem, leading to seminal works~\cite {roughgarden2021,roughgarden2024transaction} on the limitations of Bitcoin's "first-price auction" and Ethereum's EIP-1559~\cite{buterin2019eip} among others.~\cite{roughgarden2021,roughgarden2024transaction}.

A side-effect of Roughgarden's attempt to generalize about \textit{TFMs} was his pulling attention away from questions of economic efficiency and reinforcing a methodological focus on direct mechanisms and conflict motivated by \textit{strategic manipulation}. As a result, since 2021, the vast majority of academics working on \textit{TFM design} have followed Roughgarden in modelling \textit{TFMs} as two-party auctions in which producers clash with users over how to price blockspace as a private good. The attractiveness of the approach is obvious: it focuses on mechanism-imposed rather than external motivations for conflict, it targets an essential step in the formation of consensus, it avoids the complication of modelling the diffuse utility provided by public goods, and it uses a two-sided game that is tractable to mathematical analysis. As a bonus, Myerson's lemma and virtual valuations can also be used to generalize the rational strategies of participants in these two-sided games so they can be asserted to hold in larger games with many players, allowing for the generalization of conclusions to the market setting.

Since one of the purposes of this paper is to present a mechanism that evades these problems, it is necessary to show how this approach makes achieving \textit{pareto optimality} theoretically impossible. In this light, the first problem is the treatment of UIC and MIC as properties which can exist outside the context of a social choice rule. Instead of identifying an equilibrium like pareto optimality that guarantee both fee-optimality and collusion-resistance, the post-Roughgarden literature assumes that truthful preference revelation is a sufficient goal in-and-of-itself. The problem here is that the specific information users must reveal depends on the social choice rule in play, and which psychological and environmental motivations create the forms of goal conflict that mechanisms must resolve.

Viewed sympathetically, we can intuit that the field's implicit social choice rule is an "efficient allocation" of blockspace. This seems fair to assume given Roughgarden's own citation of the Vickrey-Clarke-Groves (VCG) mechanism as being UIC and the lack of any seeming challenge to this assumption. And the assumption is understandable. If the VCG auction is considered to reveal truthful information sufficient for optimizing participant utility in one context, it does seem intuitive that the same information should be sufficient to optimize utility in a different context. But this intuition is misplaced, as the types of information needed to implement an "efficient allocation" outcome in an auction setting are quite different from that required to calculate "pareto optimality" in a market context.

Note, for instance, that the VCG auction is a \textit{direct mechanism} that does not require high-dimensional preference information as part of its process of truthful preference revelation. Users share information on the maximum price-point at which they are willing to purchase the single private good being allocated given a fixed price and production schedule for everything else, not their comparative preference for how to divide their resources between all goods and services at all viable price equilibria as required for implementing \textit{pareto optimality}. The VCG auction is thus informationally inadequate for eliminating byzantine strategies motivated by \textit{self-interest} -- our first class of incentive to sub-optimality that emerges when the cost of purchasing utility from the blockchain is higher than the cost of purchasing utility outside the mechanism. Similarly, the VCG auction has no informational basis for combatting \textit{free-riding}, since cooperative strategies to defund public goods cannot be addressed by models that treat blockspace like a private good.

While this secondary problem with public goods is less prevalent in Roughgarden's work, it is a central theme in a related stream of papers from Elaine Shi and Hao Chung, whose work on \textit{side-contract payments} and the \textit{zero-revenue bound} argue that collusion between users and producers is impossible to disincentivize in any mechanism where the income for producers is above zero. While these papers disagree on the technical definition of collusion: Shi and Chung suggest the property of "side-contract proof" ("no utility increase from off-chain payments") rather than Roughgarden's more encompassing definition of OCA-Proof ("no utility increase from chain re-organization"), the difference between the two definitions is not germaine to this paper, since \textit{pareto optimality} eliminates both possibilities on the fundamental grounds that in any mechanism that implements it production is already positioned at the \textit{utility possibilities frontier} and so there is no costless strategy for increasing utility either within an alternate block or across any potential fork.

While digging into the \textit{zero-revenue bound} is somewhat tangential to our discussion of the methodological limitations of auction models, we can observe in passing that the framework of \textit{goal conflict} and particularly \textit{free-riding pressures} provides an intuitive explanation of why Hao and Chung stumble into this limitation. As discussed in our previous section, the motivating cause of suboptimal forms of user-producer collusion is the existence of two-sided free-rider problems embedded within \textit{TFM} mechanisms. The \textit{zero-revenue bound} follow deductively from this problem since at any positive fee-level users have an incentive to collude with producers to free-ride on the contributions of their peers to the security budget. This problem can be avoided by compensating producers through an inflationary block reward, but that reverses the problem by inviting producer-user collusion targeting the supply-side payout. Avoiding one trap pushes us into the other, so the only situation in which we avoid collusion completely is if neither fees nor block rewards exist. As long as this double-sided free-rider problem exists, non-excludability can only be maintained if self-provision is sacrificed.

Back on the topic of auction mechanisms, a more subtle methodological problem relates to the treatment of block producers, who are simply asked to implement the fee mechanism. From the perspective of mechanism design, the lack of any need for producers to reveal private information raises questions about why we are modelling this game as a two-sided strategic interaction. But the limitation points to a deeper methodological problem connected with the presence of public goods. For the existence of these two-sided free-rider problems makes it impossible to achieve pareto optimality if we require truthful preference revelation from only one party, as both parties have private incentives to adopt byzantine strategies driven by motivation to free-ride on the their peers. Eliminating collusion thus requires either eliminating free-riding pressures generally (impossible in auction mechanisms that model blockspace as a private good) or by identifying a kind of "private information" which can by leveraged by a mechanism to shift producer strategies away from defection and towards cooperation (impossible in mechanisms that deny producers the strategic agency to act on the basis of private information). Once again, the structural limitations of the auction mechanism precludes any ability to find a solution.

The third and most fundamental problem with the auction model is that it is impossible to generalize its results through the Revelation Principle. Since this is a somewhat subtle point, note that while Maskin teaches us that all nash equilibria which are reachable by \textit{indirect mechanisms} can be implemented as \textit{direct mechanisms}, the opposite is not true: we cannot conclude from a failure to find an equilibrium in any direct model that an indirect model does not exist which is capable of achieving this equilibrium

Understanding this point is important for seeing how the mechanism described later in this paper solves the problem. For Maskin's revelation principle is based on logical reasoning about the consistency of outcomes between decomposable algorithms (where participants compute their preferences privately) and composable algorithms (where users reveal their preferences to a centralized mechanism that does the work for them). In situations where the amount of information required to calculate an optimal solution is so large as to make disclosure impractical or impossible to calculate in a centralized mechanism or bounded messaging channel, such as exists with the high-dimensional preference data needed to compute \textit{pareto optimal} equilibria in informationally decentralized environments faced with problems of \textit{goal conflict}, \textit{indirect mechanisms} that use \textit{decomposable algorithms} to filter and transform participant preferences prior to their revelation can be informationally necessary to achieve incentive compatibility. It should be noted that Maskin's revelation principle still holds -- truthful preference revelation happens in both types of mechanism -- but it can happen in a different stage, either in the "action stage" identified by Hurwicz where bids are submitted directly to the market, or obliquely in the "pre-exchange negotiation stage" in a more indirect and filtered form.

The presence of multiple forms of contending utility is what forces the need for high-dimensional preference measurement to achieve \textit{pareto optimality}, as their existence pulls utility-optimizing strategies away from maximizing the kind of "single well-defined objective function" Hurwicz associated with computational models and towards the more complicated multivariate analysis common in economics. Perhaps because of this, it is interesting to see mechanism designers more centered in economics explicitly recognize the presence of public goods, as is the case in a recent paper by Elijah Fox, Mallesh Pai, and Max Resnick on "Censorship Resistance in On-Chain Auctions". While the assumptions these authors make are not strictly true -- they assert transaction fees are public goods while these fees only incentivize the provision of collective benefits to the extent they induce competitive spending on the security function -- these authors are absolutely correct that off-chain payments in non-atomistic markets involve a form of free-riding and addressing this problem is the key challenge for mechanism designers.

More evidence any solution will take the form of an \textit{indirect mechanism} comes from the way this class of mechanism is the preferred technique for optimizing public good provision even within auction design, such as in the curious case of the Clarke-Groves mechanism (not to be confused with the VCG mechanism), which is an indirect mechanism in which users are asked to submit bids across bundles of goods, some of which may be public goods, and where this indirect preference information is leveraged to intuit the comparative shape of the private demand curves and optimize the overall provision of utility. Given the parallels between the information requirements to solve that problem and the one facing \textit{TFM optimization}, it is likely no accident that the solution this paper identifies is an \textit{indirect mechanism} that leverages decomposabitility to avoid the need for truthful preference revelation during the "pre-exchange negotiation step" as a necessary precondition for achieving incentive compatibility.

The dominance of auction-centric analysis in recent academic work on fee mechanisms prompts a general question: what percentage of the remaining papers are writing about fee mechanisms and what percentage are simply writing about auctions? Making similar assumptions as their predecessors (auction model, no clear social choice rule, costless manipulation of informational environment), Aadityan Ganesh, Clayton Thomas and Matthew Wienberg not surprisingly end up in the same place, with the value of their work consisting mostly of new terms like "off-chain influence proofness" to describe specific forms of collusion. Interestingly, by identifying "external opportunities" for profit not captured within the auction literature, the authors are re-raising questions of overall economic efficiency by trying to model forms of utility that are external to the mechanism. Their conclusions would be more powerful if they noted that the auction model itself is the source of their problems. But if the proof-of-stake mechanisms they study cannot address any of these problems how could they -- or any of their peers -- be expected to reject the same approach?

There are nonetheless some positive results that hint at indirect market mechanisms -- not auctions -- hold the key to solving these problems. Rejecting the tendency to treat auctions as one-shot games, \citet{ferreira2021dynamic} observes that abandoning the single-step auction improves outcomes considerably. \citet{chen2022bayesian} likewise proposes a mechanism that relaxes these limitations and identifies \textit{posted-price} mechanisms as a subset of auction designs. From an economic perspective, these papers make progress against \textit{strategic manipulation} by moving pricing information into what Hurwicz referred to as the "environment" of the mechanism. The vulnerability of these techniques is of course to attacks where \textit{goal conflict} motivates attacks on this environmental information, which is costless to manipulate in any mechanism where block orphaning can be costless for any coalition of producers.

\citet{gafni2024barriers} attempt to characterize deterministic TFMs and show that repeated games are more likely to iterate towards optimal prices. While their mechanism suffers from the same limitations as other auction-centric approaches in its analysis of a single-block setting, the authors' observation that mechanisms with inertia show better performance mirrors a similar observation from Hurwicz in his analysis of price-optimization algorithms in both free markets and command economies, and hints at market-oriented solutions offering a better solution.

In general, the literature continues to be preoccupied with defining new terms to describe the extremely specific ways that the three underlying motivations for \textit{goal conflicts} manifest in their auction mechanisms, instead of focusing on the underlying reasons why \textit{goal conflict} exists in these mechanisms, asking whether any overarching equilibrium exist in which these conflicts might not exist, and what forms of information would need to be revealed or made computable in any fundamental solution capable of eliminating them generally.

