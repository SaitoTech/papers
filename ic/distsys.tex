
To our knowledge, this is the first paper to show how goal conflict prevents \textit{TFMs} from achieving \textit{pareto optimality} and makes auction models informationally incapable of resolving conflict within \textit{TFM}. In order to understand the exact problem, this section reviews how computer scientists have studied this issue to show the general issues with approaches used.

Early attempts to model \textit{TFMs} as auctions were Bitcoin-specific, starting with "Redesigning Bitcoin's Fee Market", which proposed using a "monopolistic auction" to stabilize miner revenue, followed by Andrew Yao's "An Incentive Analysis" which showed this maximized miner revenue at scale. Basu, Easley, Oâ€™Hara, Sirer then proposed a modified Vickrey-Clarke-Groves mechanism as a better choice for maximizing the collective welfare of both users and miners.

While all three papers focused explicitly on Bitcoin, the concerns over efficiency showed awareness \textit{TFMs} are not just resource allocation mechanisms, but are themselves subject to conflict over resource allocation within the broader economy! Computer science was on the cusp of seeing the underlying economic nature of their problem, identified by Hurwicz in 1973 as "goal conflict", and realizing that \textit{pareto optimality} would be the social choice rule required to solve it.

Computer science pulled back slightly in 2021 when Tim Roughgarden\citet{roughgarden2021,roughgarden2024transaction} offered a paper that modelled Transaction Fee Mechanisms (TFMs) as two-sided auctions in which block producers are given a temporary monopoly over the production of a block and must strategically allocate a subset of transactions into it. Looking beyond Bitcoin towards a landscape of competing consensus mechanisms, Roughgarden returned to characterizing the incentive-alignment issue as resulting from internal rather than economy-wide conflict over resource allocation. He was the first to highlight the difficulty of achieving incentive compatibility for both users (UIC) and block producers or miners (MIC), leading to seminal works~\cite {roughgarden2021,roughgarden2024transaction} on the limitations of Bitcoin's "first-price auction" and Ethereum's EIP-1559~\cite{buterin2019eip} among others. Roughgarden~\cite{roughgarden2021,roughgarden2024transaction}.

Since 2021, the vast majority of academics working on \textit{TFM design} have followed Roughgarden in modelling \textit{TFMs} as two-party auctions in which producers clash with users over how to allocate blockspace. The attractiveness of the approach is obvious: it focuses on internal rather than external motivations for conflict, it targets an essential step in the formation of consensus, and it uses a two-sided game that is tractable to model. Significantly, Myerson's lemma and virtual valuations can also be used to generalize the rational strategies of participants in these games so they can be asserted to hold in larger games with many players. Unfortunately, the work is simply producing a series of impossibility results.

Since one of the purposes of this paper is to present a mechanism that evades these problems, it is useful show how this choice of modeling \textit{fee mechanisms} has created structural incompatible with a productive solution. In this light, the first problem is methodological treatment of UIC and MIC as properties which can exist outside the context of a social choice rule. Instead of identifying an equilibrium like pareto optimality that guarantee both fee-optimality and collusion-resistance for users and producers alike, and asking what private information both participants would need to disclose for any \textit{direct mechanism} like an auction to achieve it, the literature assumes that truthful preference revelation is a sufficient goal in-and-of-itself. This is typically done by citing the Revelation Principle and observing that any mechanism capable of achieving a nash equilibrium must have an equivalent in which (see Roughgarden p. 13) truthful bidding is a dominant strategy.

The problem with this assumption is that the preference information any algorithm needs to be revealed depends on the social choice rule at stake, and specifically on whether we are in the presence of a problem that requires high-dimensional preferences to calculate.

Viewed sympathetically, we can intuit that the field's implicit social choice rule is an "efficient allocation" of blockspace. This seems fair to assume given Roughgarden's citation of the Vickrey-Clarke-Groves (VCG) mechanism as being UIC and the lack of any seeming challenge to this assumption. If this auction is considered to reveal truthful information sufficient for optimizing participant utility in one mechanism, it seems intuitive that it would collect the same information needed to optimize utility in a different mechanism, but the information required actually depends on the social choice rule and the difference between the types of conflict mechanisms are intended to address requires a very different type of "utility" information to be collected in our case.

Note, for instance, that the VCG auction is a \textit{direct mechanism} that does not require high-dimensional preference information as part of its process of truthful preference revelation. Users share information on the maximum price-point at which they are willing to purchase the single privte good being allocated given a fixed price and production schedule for everything else, not their comparative preference for how to divide their resources between all goods and services competing for consumption of the same transaction fee at all viable price equilibria as required for implementing \textit{pareto optimality}. The VCG auction is thus informationally inadequate for eliminating byzantine strategies motivated by "self-interest" -- our first class of incentive to suboptimality. Similarly, the VCG auction has no informational basis for combatting \textit{free-riding}, since those are cooperative strategies to defund the production of a form of utility not covered by models that treat blockspace like a private good.







Roughgarden's papers were quickly followed by papers from Elaine Shi and Hao Chung, who offered technical definitions like "side-contract proof" ("no utility increase from off-chain payments") rather than using Roughgarden's technical definition of OCA-Proof. The difference between the two is essentially the difference between whether collusion maximizes revenue in the context of a single block or across potential forks in a chain. The concept of OCA-Proof thus encompasses types of collusion that lead to block orphaning while SCP-based approaches do not. Pareto optimality eliminates both possibilities on the fundamental grounds that there is no rational strategy for colluding in either case. The mechanism proposed later in this paper also elegantly sidesteps Roughgarden's concerns that any "fee burn" must invite collusion because "because OCAs allow the miner and users to coordinate and evade the intended burn." This is of course not possible in routing work mechanisms where the burn is the cost of producing a block, as it cannot be evaded by moving the payment off-chain.





A more subtle problem applies to the treatment of block producers, who are simply asked to implement the fee mechanism. The lack of any need for producers to reveal private information raises questions about why we are modelling this game as a two-sided strategic interaction, and points to a deeper methodological problem. For as noted in our first section, the class of \textit{TFMs} we are studying contain dual-sided free-rider problems. This specific class of vulnerability makes it impossible to achieve pareto optimality for both parties if we require truthful preference revelation from only one party. For both parties have private incentives to adopt byzantine strategies that are driven by a desire to free-ride on their peers. Eliminating collusion thus requires either eliminating collective action problems generally (and the auction mechanism cannot handle this as it focuses exclusively on a single private good) or by identifying a kind of "private information" which can by leveraged by a mechanism to motivate producers to shift their strategies away from defunding fection and towards cooperation. By denying producers the ability to act strategically on the basis of private preferences, modelling blockchains as auction mechanisms leads inescapably to impossibility results as they prevent the most critical party from behaving strategically!

The third and most fundamental problem with the auction model generally is that it is impossible to generalize its impossibility results, since the existence of an impossibility proof for this specific type of \textit{direct mechanism} can never eliminate the possibility that an \textit{indirect mechanisms} might exist that can achieve the desired results through the solicitation of a different kind of preference. Since this is a somewhat subtle point, note that while Maskin's relevation principle teaches us that all nash equilibria which are reachable by \textit{indirect mechanisms} can be implemented as \textit{direct mechanisms}, the opposite is not true. So even if the auction model was informationally appropriate for implementing \textit{pareto optimality}, we cannot conclude from an impossibility proof generated assuming the limitations of a direct mechanism that no indirect mechanism exists which is capable of skirting that problem.

Understanding this point is important for seeing how the mechanism described later in this paper solves the problem. For Maskin's revelation principle is based on logical reasoning about the consistency of outcomes between decomposable algorithms (where participants compute their preferences privately) and composable algorithms (where users reveal their preferences to a centralized mechanism that does the work for them). In situations where the amount of information required to calculate an optimal solution is so large as to make disclosure impractical or impossible to calculate in a centralized mechanism, such as exists with the high-dimensional preference data needed to compute \textit{pareto optimal} equilibria in informationally decentralized environments, \textit{indirect mechanisms} that use \textit{decomposable algorithms} to filter and transform participant preferences prior to their revelation can be informationally necessary to achieve incentive compatibility. It should be noted that Maskin's revelation principle still holds -- truthful preference revelation happens in both types of mechanism -- but it can happen in a different stage, either in the "action stage" identified by Hurwicz where bids are submitted directly to the market, or obliquely in the "pre-exchange negotiation stage" in a more indirect and filtered form.

The presence of public goods in consensus mechanisms is what forces the need for high-dimensional preference measurement, as they pull focus away from maximizing the kind of "single well-defined objective function" Hurwicz associated with computational models and towards the more complicated multi-variate forms of goal conflict suitable for economic analysis. Perhaps because of this, it is not surprisingly to see mechanism designers with stronger economic backgrounds explicitly recognize the presence of public goods, as is the case in a recent paper by Elijah Fox, Mallesh Pai, and Max Resnick on "Censorship Resistance in On-Chain Auctions". While the assumptions these authors make are not strictly true -- transactions fees induce both private and public goods and only incentivize the provision of public goods to the extent they circulate openly for competitive inclusion -- these authors are absolutely correct that off-chain payments involve a form of free-riding and addressing this problem is the key challenge for mechanism designers.

While the proposal by Fox fails on technical grounds (the degree of competition for fee collection can be manipulated by collusion in any non-excludable mechanism), their insight helps explain why \textit{indirect mechanisms} are traditionally used in economics when optimizing resource allocation to non-excludable goods and eliminating free-rider pressures. \textit{Indirect mechanisms} are the preferred approach for solving these class of problems, such as in the curious case of the Clarke-Groves mechanism (not to be confused with the VCG mechanism), a indirect mechanism in which users are asked to submit bids across bundles of goods, some of which may include public goods. Given the parallels between the information requirements to solve both problems, it is likely no accident that the solution this paper identifies is an \textit{indirect mechanism} that leverages decomposabitility to avoid the need for truthful preference revelation during the "pre-exchange negotiation step" as a necessary precondition for achieving incentive compatibility.

Returning to our review of the related literature, a second influential string of papers has come from Hao Chung and Elaine Shi in their work on \textit{side-contract payments} and the \textit{zero-revenue bound}. Specifically, Hao and Chung advance claims that side-contract payments (SCP) are impossible to disincentivize in any mechanism where the income for block producers is above zero.

The same methodological problems apparent elsewhere replicate here, as Hao and Chung treat truthful preference revelation as if it is a valid social choice rule rather than an intermediary step to achieve one in the presence of private information. The most significant difference with this approach is that unlike academics who view an "efficient and fee-stable blockspace allocation" as the implicit social choice rule, for Hao and Chung it is the possibility for a collusion-free environment that takes center stage, with results suggesting that collusion is impossible to eradicate in \textit{TFMs} with revenue above the \textit{zero-revenue bound}.

The framework provided above provides an intuitive explanation of why Hao and Chung stumble into their zero-revenue bound. As explained in Section 2, the underlying source of suboptimal forms of user-producer collusion is the existence of dual-sided free-rider problems embedded in the mechanisms. Their results follow deductively from this problem. At any positive fee-level users have an incentive to collude with producers to free-ride on the contributions of their peers to the security budget. This problem can be avoided by compensating producers through an inflationary block reward, but that invites producers to free-ride on the supply-side payout. Avoiding one trap pushes us into the other, so the only situation in which we avoid collusion completely in their model is if neither fees nor block rewards exist.



What percentage of the remaining papers are writing about blockchains and what percentage are simply writing about auctions? Making similar assumptions as their predecessors (auction model, no clear social choice rule, costless manipulation of informational environment), Aadityan Ganesh, Clayton Thomas and Matthew Wienberg not surprisingly end up in the same place, with the value of their work consisting mostly of several new terms like "off-chain influence proofness" that capture specific forms of collusion. While the authors identify "external opportunities" for profit not captured within the fee mechanism (implying goal conflict), they fail to follow their observations to their obvious conclusions: that the auction model itself is an inappropriate tool for analysing this problem. But the proof-of-stake models they study cannot address any of these problems. So how could they -- or any of their peers -- be expected to find a solution, when their focus is examining mechanisms designed by developers who also fail to understand the underlying problems they face?

There are some positive results, interesting primarily for showing that market mechanisms -- not auctions -- hold the key to solving these problems. Rejecting the tendency to treat auctions as one-shot games,CITATION find that repeated-games. This works for the same reason that \citet{ferreira2021dynamic} finds -- it creates the form of "inertia" required in free markets for price levels to move closer to pareto optimal levels in equilibrium. Ferreria's finding also shows the benefit of moving pricing information into the state of consensus itself, minimizing opportunities for \textit{strategic manipulation} by shifting the market price into the environment rather than making it only accessible through unreliable peer messages.

The tendency in computer science papers to treat the conclusions of earlier papers as axioms in new lemmas intended to develop new theorems has exacerbated the tendency for impossibility results to be exaggerated and amplified. 

%%%
%%% \citet{ferreira2021dynamic} propose a posted-price TFM and provide an equilibrium posted-price at which TFMs are incentive compatible for both users and producers. \citet{chen2022bayesian} propose a TFM that guarantees BUIC and collusion resistance.
%%%
\citet{chung2023foundations} introduce a "Burning Second-price" TFM that compromises allocative efficiency to guarantee user and block producer IC. In their model, the authors tweak the utility model with "$\gamma$-Strict" utility for users/producers. The new model captures the future cost of introducing fake transactions discounted by a \textit{public} parameter $\gamma\in [0,1]$. We believe compared to  "$\gamma$-Strict" utility \ourTFM's incentive rule introduces a natural cost for introducing fake transactions to the users/producers. Moreover $\gamma$-Strict utility does not prevent free-riding.
%%% \citet{gafni2024barriers} fully characterize deterministic TFMs and show that only the trivial TFM -- that never confirms any transaction -- is IC for users and producers and is simultaneously collusion proof. \citet{chung2024collusion} shows the impossibility of satisfying Block Producer IC, User IC, and user-producer collusion-proofness in randomized TFMs. They also propose relaxations to circumvent the impossibility. Among other works, \citet{wu2023maximizing} provide an optimal bound for the block producer for a TFM that is Bayesian IC and collusion-proof, assuming that a known fraction of the users are honest. \citet{damle2024designing} instead focus on reducing transaction fees by redistributing the surplus while providing a relaxed incentive-compatibility guarantee.
%%%
%%% % \varul{
%%%\paragraph{Maximal Extractable Value (MEV).}
%%%Another developing line of work in TFMs decouples the process of block production and extracting maximal value out of the transactions (referred to as "maximal extractable value" (MEV)). \citet{bahrani2023transaction} discuss the incentive and welfare properties for Block Producers and Users considering the additional MEV value as "block producer surplus". \citet{bahrani2024transaction} introduce another type of agent, namely \emph{searchers}, that act like MEV Oracles and analyze TFMs with MEV. \citet{bahrani2024centralization} discuss the problem of centralization due to heterogeneity in knowledge among different agents. 
%%% }
%%%Informationally, what these papers seem to be establishing is that in 
%%%




